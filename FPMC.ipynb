{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 2.8051\n",
      "Epoch 2/5, Loss: 2.8036\n",
      "Epoch 3/5, Loss: 2.7655\n",
      "Epoch 4/5, Loss: 2.7888\n",
      "Epoch 5/5, Loss: 2.7560\n",
      "Recommended items: [487 577 849 105 324]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Helper functions for sigmoid and gradient\n",
    "def sigmoid(x):\n",
    "    # Clip values to prevent overflow\n",
    "    x = np.clip(x, -500, 500)\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# FPMC Model\n",
    "class FPMC:\n",
    "    def __init__(self, num_users, num_items, num_factors, learning_rate=0.001, reg=10):\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.num_factors = num_factors\n",
    "        self.learning_rate = learning_rate\n",
    "        self.reg = reg\n",
    "        \n",
    "        # Latent factor matrices for users and items\n",
    "        self.U = np.random.normal(scale=1./num_factors, size=(num_users, num_factors))  # User preferences\n",
    "        self.V = np.random.normal(scale=1./num_factors, size=(num_items, num_factors))  # Item latent vectors\n",
    "        self.H = np.random.normal(scale=1./num_factors, size=(num_items, num_factors))  # Item transition vectors\n",
    "\n",
    "    def predict(self, u, i, j):\n",
    "        \"\"\"\n",
    "        Predict the score for user u interacting with item j after item i.\n",
    "        P(u, j | i) = <U_u, V_j> + <V_i, H_j>\n",
    "        \"\"\"\n",
    "        user_preference = np.dot(self.U[u], self.V[j])  # User preferences for item j\n",
    "        item_transition = np.dot(self.V[i], self.H[j])   # Sequential transition from i to j\n",
    "        return user_preference + item_transition\n",
    "    \n",
    "    def train(self, user_item_seq, num_epochs=10):\n",
    "        \"\"\"\n",
    "        Train the FPMC model using pairwise ranking optimization.\n",
    "        \n",
    "        :param user_item_seq: List of tuples (user, current_item, next_item)\n",
    "        :param num_epochs: Number of training epochs\n",
    "        \"\"\"\n",
    "        for epoch in range(num_epochs):\n",
    "            total_loss = 0\n",
    "            for (u, i, j) in user_item_seq:\n",
    "                # Random negative sample (a wrong next item)\n",
    "                k = np.random.randint(self.num_items)\n",
    "                while k == j:\n",
    "                    k = np.random.randint(self.num_items)\n",
    "                \n",
    "                # Predict the scores for correct and incorrect next items\n",
    "                correct_score = self.predict(u, i, j)\n",
    "                incorrect_score = self.predict(u, i, k)\n",
    "                \n",
    "                # Compute the loss and gradients using sigmoid ranking loss\n",
    "                delta = sigmoid(correct_score - incorrect_score)\n",
    "                total_loss += -np.log(delta)\n",
    "                \n",
    "                # Update user, item, and transition factors using gradient descent\n",
    "                self.U[u] += self.learning_rate * (delta * (self.V[j] - self.V[k]) - self.reg * self.U[u])\n",
    "                self.V[j] += self.learning_rate * (delta * (self.U[u] + self.V[i] - self.H[k]) - self.reg * self.V[j])\n",
    "                self.V[k] += self.learning_rate * (-delta * self.U[u] - self.reg * self.V[k])\n",
    "                self.H[j] += self.learning_rate * (delta * self.V[i] - self.reg * self.H[j])\n",
    "                self.H[k] += self.learning_rate * (-delta * self.V[i] - self.reg * self.H[k])\n",
    "                self.V[i] += self.learning_rate * (delta * (self.H[j] - self.H[k]) - self.reg * self.V[i])\n",
    "\n",
    "            print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss:.4f}')\n",
    "    \n",
    "    def recommend(self, u, i, top_n=5):\n",
    "        \"\"\"\n",
    "        Recommend top N items for user u after interacting with item i.\n",
    "        \"\"\"\n",
    "        scores = [self.predict(u, i, j) for j in range(self.num_items)]\n",
    "        top_items = np.argsort(scores)[-top_n:][::-1]\n",
    "        return top_items\n",
    "\n",
    "# Example usage:\n",
    "num_users = 100  # Number of users in the dataset\n",
    "num_items = 1000  # Number of items in the dataset\n",
    "num_factors = 10  # Latent factor size\n",
    "\n",
    "# Initialize FPMC model\n",
    "fpmc_model = FPMC(num_users, num_items, num_factors)\n",
    "\n",
    "# Example user-item sequence for training (user_id, current_item_id, next_item_id)\n",
    "user_item_seq = [(0, 10, 15), (1, 20, 25), (0, 15, 18), (2, 30, 35)]  # Replace with actual user-item interactions\n",
    "\n",
    "# Train the model\n",
    "fpmc_model.train(user_item_seq, num_epochs=5)\n",
    "\n",
    "# Recommend next items for user 0 after interacting with item 10\n",
    "recommendations = fpmc_model.recommend(0, 10, top_n=5)\n",
    "print(f'Recommended items: {recommendations}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    # Clip values to prevent overflow\n",
    "    x = np.clip(x, -500, 500)\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def clip_gradients(gradient, threshold=1):\n",
    "    # Clip the gradients to avoid explosion\n",
    "    norm = np.linalg.norm(gradient, ord=2)\n",
    "    if norm > threshold:\n",
    "        gradient = gradient * threshold / norm\n",
    "    return gradient\n",
    "\n",
    "class FPMC:\n",
    "    def __init__(self, num_users, num_items, num_factors, learning_rate=0.001, reg=10):\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.num_factors = num_factors\n",
    "        self.learning_rate = learning_rate\n",
    "        self.reg = reg\n",
    "        \n",
    "        # Latent factor matrices for users and items\n",
    "        self.U = np.random.normal(scale=1./num_factors, size=(num_users, num_factors))  # User preferences\n",
    "        self.V = np.random.normal(scale=1./num_factors, size=(num_items, num_factors))  # Item latent vectors\n",
    "        self.H = np.random.normal(scale=1./num_factors, size=(num_items, num_factors))  # Item transition vectors\n",
    "\n",
    "    def predict(self, u, i, j):\n",
    "        \"\"\"Predict the score for user u interacting with item j after item i.\"\"\"\n",
    "        user_preference = np.dot(self.U[u], self.V[j])  # User preferences for item j\n",
    "        item_transition = np.dot(self.V[i], self.H[j])   # Sequential transition from i to j\n",
    "        return user_preference + item_transition\n",
    "    \n",
    "    def train(self, user_item_seq, num_epochs=10):\n",
    "        \"\"\"Train the FPMC model using pairwise ranking optimization.\"\"\"\n",
    "        for epoch in range(num_epochs):\n",
    "            total_loss = 0\n",
    "            for (u, i, j) in user_item_seq:\n",
    "                # Random negative sample (a wrong next item)\n",
    "                k = np.random.randint(self.num_items)\n",
    "                while k == j:\n",
    "                    k = np.random.randint(self.num_items)\n",
    "                \n",
    "                # Predict the scores for correct and incorrect next items\n",
    "                correct_score = self.predict(u, i, j)\n",
    "                incorrect_score = self.predict(u, i, k)\n",
    "                \n",
    "                # Compute the loss and gradients using sigmoid ranking loss\n",
    "                delta = sigmoid(correct_score - incorrect_score)\n",
    "                delta = np.clip(delta, 1e-10, 1-1e-10)  # Prevent log(0)\n",
    "                total_loss += -np.log(delta)\n",
    "                \n",
    "                # Update user, item, and transition factors using gradient descent\n",
    "                self.U[u] += self.learning_rate * clip_gradients(delta * (self.V[j] - self.V[k]) - self.reg * self.U[u])\n",
    "                self.V[j] += self.learning_rate * clip_gradients(delta * (self.U[u] + self.V[i] - self.H[k]) - self.reg * self.V[j])\n",
    "                self.V[k] += self.learning_rate * clip_gradients(-delta * self.U[u] - self.reg * self.V[k])\n",
    "                self.H[j] += self.learning_rate * clip_gradients(delta * self.V[i] - self.reg * self.H[j])\n",
    "                self.H[k] += self.learning_rate * clip_gradients(-delta * self.V[i] - self.reg * self.H[k])\n",
    "                self.V[i] += self.learning_rate * clip_gradients(delta * (self.H[j] - self.H[k]) - self.reg * self.V[i])\n",
    "\n",
    "            print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss:.4f}')\n",
    "    \n",
    "    def recommend(self, u, i, top_n=5):\n",
    "        \"\"\"Recommend top N items for user u after interacting with item i.\"\"\"\n",
    "        scores = [self.predict(u, i, j) for j in range(self.num_items)]\n",
    "        top_items = np.argsort(scores)[-top_n:][::-1]\n",
    "        return top_items\n",
    "\n",
    "# Example usage of the FPMC class would involve initializing the class with user and item counts, training on sequences of user-item interactions, and using the model to make recommendations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       userId  movieId                                              title  \\\n",
      "5540        1      804                               She's the One (1996)   \n",
      "7557        1     1210  Star Wars: Episode VI - Return of the Jedi (1983)   \n",
      "10740       1     2018                                       Bambi (1942)   \n",
      "13084       1     2628   Star Wars: Episode I - The Phantom Menace (1999)   \n",
      "13823       1     2826                           13th Warrior, The (1999)   \n",
      "\n",
      "                         genres  rating  timestamp  \n",
      "5540             Comedy|Romance     4.0  964980499  \n",
      "7557    Action|Adventure|Sci-Fi     5.0  964980499  \n",
      "10740  Animation|Children|Drama     5.0  964980523  \n",
      "13084   Action|Adventure|Sci-Fi     4.0  964980523  \n",
      "13823  Action|Adventure|Fantasy     4.0  964980523  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the MovieLens dataset (ratings and movies)\n",
    "ratings = pd.read_csv('/home/manishn/recommend/data/ml-latest-small/ratings.csv')\n",
    "movies = pd.read_csv('/home/manishn/recommend/data/ml-latest-small/movies.csv')\n",
    "\n",
    "# Merge the ratings and movies data\n",
    "merged_df = pd.merge(ratings, movies, on='movieId')\n",
    "merged_df = merged_df[['userId', 'movieId', 'title', 'genres', 'rating', 'timestamp']]\n",
    "\n",
    "# Sort the data by userId and timestamp to simulate the sequence of interactions\n",
    "merged_df = merged_df.sort_values(by=['userId', 'timestamp'])\n",
    "\n",
    "# Display the first few rows to check\n",
    "print(merged_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mappings for userId and movieId\n",
    "unique_users = merged_df['userId'].unique()\n",
    "unique_movies = merged_df['movieId'].unique()\n",
    "\n",
    "# Create dictionaries to map original IDs to sequential indices\n",
    "user_id_map = {original_id: idx for idx, original_id in enumerate(unique_users)}\n",
    "movie_id_map = {original_id: idx for idx, original_id in enumerate(unique_movies)}\n",
    "\n",
    "# Apply the mapping to the dataset\n",
    "merged_df['userId'] = merged_df['userId'].map(user_id_map)\n",
    "merged_df['movieId'] = merged_df['movieId'].map(movie_id_map)\n",
    "\n",
    "# Now userId and movieId are sequential, starting from 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0, 1), (0, 1, 2), (0, 2, 3), (0, 3, 4), (0, 4, 5)]\n"
     ]
    }
   ],
   "source": [
    "# Prepare the data: Create user-item sequences\n",
    "user_item_sequences = []\n",
    "\n",
    "# Iterate through each user's rating sequence\n",
    "for user_id, group in merged_df.groupby('userId'):\n",
    "    movie_sequence = list(group['movieId'])  # Get the sequence of movies watched by the user\n",
    "    for i in range(len(movie_sequence) - 1):  # Create transitions\n",
    "        current_movie = movie_sequence[i]\n",
    "        next_movie = movie_sequence[i + 1]\n",
    "        user_item_sequences.append((user_id, current_movie, next_movie))\n",
    "\n",
    "# Example user-item sequence  (user_id, current_item_id, next_item_id)\n",
    "print(user_item_sequences[:5])  # Output the first 5 transitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Loss: 69471.3905\n",
      "Epoch 2/30, Loss: 69471.3062\n",
      "Epoch 3/30, Loss: 69471.3040\n",
      "Epoch 4/30, Loss: 69471.3354\n",
      "Epoch 5/30, Loss: 69471.3352\n",
      "Epoch 6/30, Loss: 69471.3393\n",
      "Epoch 7/30, Loss: 69471.3426\n",
      "Epoch 8/30, Loss: 69471.3467\n",
      "Epoch 9/30, Loss: 69471.3499\n",
      "Epoch 10/30, Loss: 69471.3544\n",
      "Epoch 11/30, Loss: 69471.3570\n",
      "Epoch 12/30, Loss: 69471.3591\n",
      "Epoch 13/30, Loss: 69471.3625\n",
      "Epoch 14/30, Loss: 69471.3630\n",
      "Epoch 15/30, Loss: 69471.3639\n",
      "Epoch 16/30, Loss: 69471.3649\n",
      "Epoch 17/30, Loss: 69471.3660\n",
      "Epoch 18/30, Loss: 69471.3664\n",
      "Epoch 19/30, Loss: 69471.3671\n",
      "Epoch 20/30, Loss: 69471.3677\n",
      "Epoch 21/30, Loss: 69471.3679\n",
      "Epoch 22/30, Loss: 69471.3682\n",
      "Epoch 23/30, Loss: 69471.3684\n",
      "Epoch 24/30, Loss: 69471.3686\n",
      "Epoch 25/30, Loss: 69471.3688\n",
      "Epoch 26/30, Loss: 69471.3688\n",
      "Epoch 27/30, Loss: 69471.3690\n",
      "Epoch 28/30, Loss: 69471.3690\n",
      "Epoch 29/30, Loss: 69471.3691\n",
      "Epoch 30/30, Loss: 69471.3691\n"
     ]
    }
   ],
   "source": [
    "# Initialize the FPMC model with the correct number of users and movies\n",
    "num_users = merged_df['userId'].nunique()  # Number of unique users\n",
    "num_items = merged_df['movieId'].nunique()  # Number of unique movies\n",
    "\n",
    "fpmc_model = FPMC(num_users=num_users, num_items=num_items, num_factors=200)\n",
    "\n",
    "# Train the model with the user-item sequences\n",
    "fpmc_model.train(user_item_sequences, num_epochs=30)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "182293",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m current_movie_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m  \u001b[38;5;66;03m# Example current movie (index in sequential mapping)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Get the top 5 recommendations\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m recommended_movies \u001b[38;5;241m=\u001b[39m \u001b[43mget_movie_recommendations\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_movie_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_n\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Print the original movieId and title for the recommended movies\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecommended movies for user\u001b[39m\u001b[38;5;124m\"\u001b[39m, user_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mafter movie\u001b[39m\u001b[38;5;124m\"\u001b[39m, movie_id_to_title[reverse_movie_id_map[current_movie_id]] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[36], line 10\u001b[0m, in \u001b[0;36mget_movie_recommendations\u001b[0;34m(user_id, current_movie_id, top_n)\u001b[0m\n\u001b[1;32m      7\u001b[0m recommended_movie_indices \u001b[38;5;241m=\u001b[39m fpmc_model\u001b[38;5;241m.\u001b[39mrecommend(user_id, current_movie_id, top_n\u001b[38;5;241m=\u001b[39mtop_n)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Map back to original movieId and title\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m recommended_movies \u001b[38;5;241m=\u001b[39m [(reverse_movie_id_map[movie_idx], movie_id_to_title[reverse_movie_id_map[movie_idx]]) \n\u001b[1;32m     11\u001b[0m                       \u001b[38;5;28;01mfor\u001b[39;00m movie_idx \u001b[38;5;129;01min\u001b[39;00m recommended_movie_indices]\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m recommended_movies\n",
      "Cell \u001b[0;32mIn[36], line 10\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      7\u001b[0m recommended_movie_indices \u001b[38;5;241m=\u001b[39m fpmc_model\u001b[38;5;241m.\u001b[39mrecommend(user_id, current_movie_id, top_n\u001b[38;5;241m=\u001b[39mtop_n)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Map back to original movieId and title\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m recommended_movies \u001b[38;5;241m=\u001b[39m [(reverse_movie_id_map[movie_idx], \u001b[43mmovie_id_to_title\u001b[49m\u001b[43m[\u001b[49m\u001b[43mreverse_movie_id_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmovie_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m) \n\u001b[1;32m     11\u001b[0m                       \u001b[38;5;28;01mfor\u001b[39;00m movie_idx \u001b[38;5;129;01min\u001b[39;00m recommended_movie_indices]\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m recommended_movies\n",
      "\u001b[0;31mKeyError\u001b[0m: 182293"
     ]
    }
   ],
   "source": [
    "# Create reverse mappings to map indices back to original movieId and titles\n",
    "reverse_movie_id_map = {idx: original_id for original_id, idx in movie_id_map.items()}\n",
    "movie_id_to_title = dict(zip(merged_df['movieId'], merged_df['title']))\n",
    "# Function to get original movieId and title from the recommended indices\n",
    "def get_movie_recommendations(user_id, current_movie_id, top_n=5):\n",
    "    # Get the recommended movie indices\n",
    "    recommended_movie_indices = fpmc_model.recommend(user_id, current_movie_id, top_n=top_n)\n",
    "    \n",
    "    # Map back to original movieId and title\n",
    "    recommended_movies = [(reverse_movie_id_map[movie_idx], movie_id_to_title[reverse_movie_id_map[movie_idx]]) \n",
    "                          for movie_idx in recommended_movie_indices]\n",
    "    \n",
    "    return recommended_movies\n",
    "# Example: Recommend movies for user 0 after watching movie with index 10 (based on sequential mapping)\n",
    "user_id = 0  # Example user\n",
    "current_movie_id = 10  # Example current movie (index in sequential mapping)\n",
    "\n",
    "# Get the top 5 recommendations\n",
    "recommended_movies = get_movie_recommendations(user_id, current_movie_id, top_n=5)\n",
    "\n",
    "# Print the original movieId and title for the recommended movies\n",
    "print(\"Recommended movies for user\", user_id, \"after movie\", movie_id_to_title[reverse_movie_id_map[current_movie_id]] + \":\")\n",
    "for movie_id, title in recommended_movies:\n",
    "    print(f\"Movie ID: {movie_id}, Title: {title}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
